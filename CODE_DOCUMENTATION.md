# ğŸ“‹ AI Audio Transcription App - Complete Code Documentation

## ğŸ¯ Project Overview

This is a **Next.js + Socket.IO** real-time audio transcription application that records meeting audio in the browser and processes it with Google Generative AI (Gemini) for transcription and summarization.

**Key Features:**
- ğŸ¤ Browser-based audio recording (WebM format)
- ğŸ”Œ Real-time Socket.IO streaming to backend
- ğŸ“ Live transcription during recording
- âœ¨ AI-powered summaries with Gemini
- ğŸ”„ Automatic session resumption after disconnects
- ğŸ’¾ PostgreSQL persistence with Prisma ORM
- ğŸ‘¤ User authentication with Better Auth
- ğŸ“Š Chunk buffering during network outages

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ app/                          # Next.js frontend (port 3000)
â”‚   â”œâ”€â”€ page.tsx                  # Auth UI (sign in/up)
â”‚   â”œâ”€â”€ layout.tsx                # Root layout wrapper
â”‚   â”œâ”€â”€ globals.css               # Global styles
â”‚   â”œâ”€â”€ favicon.ico
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ client/
â”‚   â”‚       â”œâ”€â”€ AudioRecorder.tsx # Recording UI component
â”‚   â”‚       â”œâ”€â”€ hooks/
â”‚   â”‚       â”‚   â””â”€â”€ useAudioStream.ts # Core recording logic
â”‚   â”‚       â””â”€â”€ machines/
â”‚   â”‚           â””â”€â”€ recorderMachine.ts # XState state machine
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ auth/[...all]/route.ts # Better Auth endpoints
â”‚   â””â”€â”€ lib/
â”‚       â”œâ”€â”€ auth.ts               # Better Auth config
â”‚       â””â”€â”€ auth-client.ts        # Client-side auth
â”‚
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ server.ts                 # Socket.IO server (port 4000)
â”‚   â”œâ”€â”€ temp/                     # Temp audio files directory
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ prisma/
â”‚   â”œâ”€â”€ schema.prisma             # Database schema
â”‚   â””â”€â”€ migrations/               # DB migrations
â”‚
â”œâ”€â”€ public/                       # Static assets
â”‚   â””â”€â”€ *.svg
â”‚
â”œâ”€â”€ package.json                  # Dependencies
â”œâ”€â”€ tsconfig.json                 # TypeScript config
â”œâ”€â”€ next.config.ts                # Next.js config
â”œâ”€â”€ eslint.config.mjs             # ESLint rules
â”œâ”€â”€ postcss.config.mjs            # PostCSS config
â”œâ”€â”€ .env                          # Environment variables
â”œâ”€â”€ README.md                     # Quick start guide
â”œâ”€â”€ SETUP_SUMMARY.md              # Setup instructions
â”œâ”€â”€ BUG_FIXES.md                  # Known issues
â”œâ”€â”€ FLOW_DIAGRAMS.md              # Visual flow diagrams
â””â”€â”€ CODE_DOCUMENTATION.md         # This file
```

---

## ğŸ—ï¸ System Architecture

### **High-Level Flow**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           NEXT.JS CLIENT (React) - Port 3000                 â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  page.tsx      â”‚         â”‚  AudioRecorder   â”‚             â”‚
â”‚  â”‚  (Auth UI)     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤  (Recording UI)  â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                      â–²                        â”‚
â”‚  useSession() â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                       â”‚
â”‚  (Better Auth)                    â”‚  â”‚                       â”‚
â”‚                            useAudioStream Hook               â”‚
â”‚                                 (CORE LOGIC)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ â€¢ Socket.IO connection (lazy-loaded)                â”‚   â”‚
â”‚  â”‚ â€¢ MediaRecorder API (audio capture)                 â”‚   â”‚
â”‚  â”‚ â€¢ Chunk buffering (network resilience)              â”‚   â”‚
â”‚  â”‚ â€¢ XState machine (state management)                 â”‚   â”‚
â”‚  â”‚ â€¢ localStorage (session persistence)                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    Socket.IO (WebSocket/Polling)
                                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           NODE.JS SERVER (Express) - Port 4000               â”‚
â”‚                                                               â”‚
â”‚  server.ts (Socket.IO Handler)                               â”‚
â”‚  â”œâ”€ start-session      â†’ Create session, open file           â”‚
â”‚  â”œâ”€ audio-chunk        â†’ Write to .webm, buffer live         â”‚
â”‚  â”œâ”€ stop-session       â†’ Upload to Gemini, get summary       â”‚
â”‚  â”œâ”€ pause-session      â†’ Pause MediaRecorder                 â”‚
â”‚  â””â”€ disconnect         â†’ Cleanup, close streams              â”‚
â”‚                                                               â”‚
â”‚  Processing Pipeline:                                        â”‚
â”‚  1. Receive audio chunks every 1000ms                        â”‚
â”‚  2. Write to temp file                                       â”‚
â”‚  3. Every 5s: buffer 5KB and send to Gemini for live text    â”‚
â”‚  4. On stop: upload full file for final summary              â”‚
â”‚  5. Save results to PostgreSQL                               â”‚
â”‚  6. Emit to client                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                           PostgreSQL (Neon)
                                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           DATABASE (PostgreSQL)                              â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ users        â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤ recordings       â”‚              â”‚
â”‚  â”‚ (auth)       â”‚ userId  â”‚ (audio metadata) â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                               â”‚
â”‚  Recording Fields: status, transcript, summary, timestamps   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”‘ Core Components Deep Dive

### **1. [`app/page.tsx`](app/page.tsx ) - Authentication Page**

**Purpose:** Sign up/Sign in interface using Better Auth

**User Flow:**
```
1. User loads app
2. Check if session exists (useSession hook)
3. If YES â†’ Show AudioRecorder
4. If NO â†’ Show auth form (email + password)
5. User clicks "Create Account" or "Sign In"
6. Form validates inputs
7. Better Auth processes request
8. Session created â†’ AudioRecorder displays
```

**Key State:**
```typescript
email           // Input: user@example.com
password        // Input: secure password
name            // Input: Full Name (sign up only)
isSignUp        // Toggle: "Sign In" â†” "Create Account"
isLoadingAuth   // Loading spinner during auth
errors          // Validation errors: { email?, password?, name? }
```

**Key Functions:**
```typescript
validateForm()  // Check email format, password length, name (sign up)
handleAuth()    // Call signIn.email() or signUp.email()
```

**Conditional Rendering:**
```typescript
if (isPending) return <LoadingSpinner /> // Session check in progress

if (session?.user) return <AudioRecorder /> // User authenticated

return <AuthForm />  // User not authenticated
```

---

### **2. [`app/components/client/AudioRecorder.tsx`](app/components/client/AudioRecorder.tsx ) - Recording UI**

**Purpose:** Visual interface for recording controls and status display

**States & Their UI:**

| State | Indicator | Buttons | Display |
|-------|-----------|---------|---------|
| **idle** | â— Gray | Start Recording | â€” |
| **recording** | â— Red (pulsing) | Pause, Stop | Waveform animation + live transcript |
| **paused** | â— Blue (pulsing) | Resume, Stop | â€” |
| **reconnecting** | â— Yellow (pulsing) | Pause, Stop | "Reconnecting..." banner + buffered count |
| **processing** | â— Purple (pulsing) | â€” | Spinner + "Processing with AI..." |
| **success** | â— Green | New Recording | AI Summary box + Copy button |
| **error** | â— Red | Try Again | Error message box |

**UI Components Breakdown:**

#### **1. Reconnection Banner** (only when `isReconnecting`)
```tsx
<div className="bg-yellow-500/10 border border-yellow-500/50 rounded-lg p-4">
  <p className="text-yellow-400">Connection Stable</p>
  <p className="text-yellow-400/70">Reconnecting... (3 chunks buffered)</p>
</div>
```

#### **2. Status Indicator**
```tsx
<div className="flex items-center gap-2">
  {/* Status dot */}
  <div className={`w-3 h-3 rounded-full ${
    isRecording ? 'bg-red-500 animate-pulse' :
    isReconnecting ? 'bg-yellow-500 animate-pulse' :
    isProcessing ? 'bg-purple-500 animate-pulse' :
    isSuccess ? 'bg-green-500' :
    isError ? 'bg-red-600' :
    isPaused ? 'bg-blue-400' :
    'bg-gray-500'
  }`} />
  
  {/* Status text */}
  <span className="text-gray-200 uppercase">
    {isReconnecting ? 'RECONNECTING' : status}
  </span>
  
  {/* Buffered chunk count */}
  {queuedChunks > 0 && (
    <span className="ml-auto text-xs bg-yellow-500/20">
      ğŸ“¦ {queuedChunks} buffered
    </span>
  )}
</div>
```

#### **3. Error Display** (when `isError`)
```tsx
{isError && error && (
  <div className="bg-red-900/30 border border-red-500 rounded-lg p-4">
    <p className="text-red-400 font-semibold">âš ï¸ Error</p>
    <p className="text-red-300 text-sm">{error}</p>
  </div>
)}
```

#### **4. Live Transcript** (during recording)
```tsx
{isRecording && liveTranscript && (
  <div className="p-4 bg-blue-900/20 border border-blue-500/30 rounded-lg">
    <div className="flex items-center gap-2 mb-2">
      <span className="text-blue-400 font-semibold">ğŸ“ Live Transcription</span>
      <div className="w-2 h-2 bg-blue-500 animate-pulse"></div>
    </div>
    <p className="text-gray-300 text-sm whitespace-pre-wrap">
      {liveTranscript}
    </p>
  </div>
)}
```

#### **5. Waveform Visualizer** (during recording)
```tsx
<div className="h-16 flex items-center gap-1">
  {isRecording && [1,2,3,4,5].map(i => (
    <div 
      key={i} 
      className="w-1 bg-blue-500 h-8 animate-bounce" 
      style={{ animationDelay: `${i * 0.1}s` }} 
    />
  ))}
</div>
```

#### **6. Processing Spinner** (when processing)
```tsx
{isProcessing && (
  <div className="flex flex-col items-center gap-3">
    <div className="w-12 h-12 border-4 border-purple-500 border-t-transparent rounded-full animate-spin"></div>
    <p className="text-purple-400">â³ Processing with AI...</p>
    <p className="text-purple-300/70 text-xs">Transcribing and generating summary</p>
  </div>
)}
```

#### **7. Control Buttons**
```tsx
{/* Start/New/Retry */}
{(status === 'idle' || isError || isSuccess) && (
  <button onClick={startRecording}>
    {isError ? 'Try Again' : isSuccess ? 'New Recording' : 'Start Recording'}
  </button>
)}

{/* Pause/Resume + Stop */}
{(isRecording || isPaused || isReconnecting) && (
  <>
    {isPaused ? (
      <button onClick={resumeRecording}>Resume</button>
    ) : (
      <button onClick={pauseRecording} disabled={isReconnecting}>
        Pause
      </button>
    )}
    <button onClick={stopRecording}>Stop</button>
  </>
)}
```

#### **8. AI Summary Display** (on success)
```tsx
{summary && isSuccess && (
  <div className="p-6 bg-purple-900/30 border border-purple-500/30 rounded-xl">
    <div className="flex items-center gap-2 mb-4">
      <span className="text-2xl">âœ¨</span>
      <h3 className="text-xl font-bold text-purple-300">AI Summary</h3>
    </div>
    
    <div className="text-gray-200 whitespace-pre-wrap text-sm">
      {summary}
    </div>
    
    <button 
      onClick={() => navigator.clipboard.writeText(summary)}
      className="mt-4 px-4 py-2 bg-purple-600 hover:bg-purple-500"
    >
      ğŸ“‹ Copy Summary
    </button>
  </div>
)}
```

---

### **3. [`app/components/client/hooks/useAudioStream.ts`](app/components/client/hooks/useAudioStream.ts ) - Core Recording Logic**

**This is the heart of the application.** It handles:
- Socket.IO connection lifecycle
- MediaRecorder setup and audio capture
- Chunk buffering and flushing
- XState machine dispatch
- Database integration via server

#### **Constants & Setup**
```typescript
const SOCKET_URL = 'http://localhost:4000';
const CHUNK_INTERVAL_MS = 1000;  // Send chunk every 1 second
const SESSION_STORAGE_KEY = 'currentSessionId';

// Refs for non-state data
const socketRef = useRef<Socket | null>(null);
const mediaRecorderRef = useRef<MediaRecorder | null>(null);
const streamRef = useRef<MediaStream | null>(null);
const audioChunkQueueRef = useRef<Blob[]>([]);
const chunkIntervalRef = useRef<NodeJS.Timeout | null>(null);
```

#### **Socket Initialization** (once per session)
```typescript
useEffect(() => {
  if (!session?.user?.id) return; // Don't connect if not logged in
  
  // Create socket with lazy connection
  socketRef.current = io(SOCKET_URL, {
    autoConnect: false,           // âœ… Don't connect immediately
    transports: ['websocket', 'polling'],
    reconnection: true,
    reconnectionAttempts: 10,
    reconnectionDelay: 1000,
  });
  
  const socket = socketRef.current;
  
  // Event: Connected
  socket.on('connect', () => {
    console.log('âœ… Socket Connected');
    setIsConnected(true);
    
    // âœ… CRITICAL: Flush buffered chunks
    if (audioChunkQueueRef.current.length > 0) {
      console.log(`ğŸ“¤ Flushing ${audioChunkQueueRef.current.length} buffered chunks`);
      audioChunkQueueRef.current.forEach(chunk => {
        socket.emit('audio-chunk', chunk);
      });
      audioChunkQueueRef.current = [];
      setQueuedChunks(0);
    }
  });
  
  // Event: Disconnected
  socket.on('disconnect', (reason) => {
    console.log('âš ï¸ Socket Disconnected:', reason);
    setIsConnected(false);
    // Still recording? â†’ switch to buffering mode
  });
  
  // Event: Live transcription chunk from server
  socket.on('live-transcript', (data) => {
    setLiveTranscript(prev => prev + ' ' + data.text);
  });
  
  // Event: Final summary ready
  socket.on('processing-complete', (data) => {
    setSummary(data.summary);
    send({ type: 'COMPLETE' }); // â†’ 'success' state
  });
  
  // Event: Error from server
  socket.on('error', (data) => {
    console.error('Server error:', data);
    send({ type: 'ERROR', error: data.message });
  });
  
  // Cleanup
  return () => {
    console.log('ğŸ§¹ Cleaning up socket');
    socket.disconnect();
  };
}, [session?.user?.id]); // Only re-run if user ID changes
```

#### **Auto-Resume on Tab Refresh** (once per mount)
```typescript
useEffect(() => {
  // Check if there's a saved session
  const existingSessionId = typeof window !== 'undefined'
    ? localStorage.getItem(SESSION_STORAGE_KEY)
    : null;
  
  const wasRecording = typeof window !== 'undefined'
    ? localStorage.getItem('wasRecording') === 'true'
    : false;
  
  // If user was recording before refresh AND logged in
  if (existingSessionId && wasRecording && session?.user?.id && state.value === 'idle') {
    // âœ… Prevent infinite loop: clear flag immediately
    localStorage.removeItem('wasRecording');
    
    // Wait 1.5s before resuming (for safety)
    const timer = setTimeout(() => {
      console.log(`ğŸ”„ Auto-resuming session: ${existingSessionId}`);
      startRecording(); // Calls with existing sessionId
    }, 1500);
    
    return () => clearTimeout(timer);
  }
}, [session?.user?.id]); // Only run when user logs in
```

#### **Start Recording Function** (called when user clicks button)
```typescript
const startRecording = useCallback(async () => {
  try {
    console.log('ğŸ¤ Starting recording...');
    send({ type: 'START', sessionId: `session-${Date.now()}` });
    
    // âœ… FIX: Connect socket if not connected (lazy connection)
    if (socketRef.current && !socketRef.current.connected) {
      console.log('ğŸ”Œ Connecting socket...');
      socketRef.current.connect();
      
      // Wait for actual connection (max 5 seconds)
      await new Promise((resolve, reject) => {
        const timeout = setTimeout(
          () => reject(new Error('Socket connection timeout')), 
          5000
        );
        
        socketRef.current!.once('connect', () => {
          clearTimeout(timeout);
          resolve(true);
        });
        
        socketRef.current!.once('connect_error', (err) => {
          clearTimeout(timeout);
          reject(err);
        });
      });
    }
    
    // 1. Request microphone permission
    const stream = await navigator.mediaDevices.getUserMedia({ 
      audio: true 
    });
    streamRef.current = stream;
    
    // 2. Create MediaRecorder
    const mediaRecorder = new MediaRecorder(stream, { 
      mimeType: 'audio/webm' 
    });
    mediaRecorderRef.current = mediaRecorder;
    
    // 3. Create or resume session
    const existingSession = typeof window !== 'undefined'
      ? localStorage.getItem(SESSION_STORAGE_KEY)
      : null;
    
    const sessionId = existingSession || `session-${Date.now()}`;
    const isResume = !!existingSession;
    
    if (typeof window !== 'undefined') {
      localStorage.setItem(SESSION_STORAGE_KEY, sessionId);
      localStorage.setItem('wasRecording', 'true');
    }
    
    console.log(isResume 
      ? `ğŸ”„ Resuming session: ${sessionId}` 
      : `ğŸ™ï¸ New session: ${sessionId}`
    );
    
    const userId = session?.user?.id || 'anonymous';
    
    // 4. Tell server to start session
    socketRef.current?.emit('start-session', {
      sessionId,
      isResume,
      userId
    });
    
    // 5. Setup chunk capture and send
    let isFirstChunk = true;
    
    mediaRecorder.ondataavailable = (event) => {
      if (event.data.size === 0) return;
      
      // Skip WebM header on resume
      if (!isFirstChunk || !isResume) {
        if (socketRef.current?.connected) {
          // Connected: send immediately
          socketRef.current.emit('audio-chunk', event.data);
          console.log(`ğŸ“¤ Sent chunk (${event.data.size} bytes)`);
        } else {
          // Disconnected: buffer locally
          audioChunkQueueRef.current.push(event.data);
          setQueuedChunks(q => q + 1);
          console.log(`ğŸ“¦ Buffering chunk (disconnected) - ${audioChunkQueueRef.current.length} queued`);
        }
      }
      isFirstChunk = false;
    };
    
    // 6. Start recording (capture every 1000ms)
    mediaRecorder.start(CHUNK_INTERVAL_MS);
    console.log('â–¶ï¸ Recording started');
    
  } catch (error) {
    console.error('Start recording error:', error);
    const errorMsg = error instanceof Error ? error.message : 'Unknown error';
    
    // Distinguish between different error types
    let displayError = errorMsg;
    if (errorMsg.includes('NotAllowedError')) {
      displayError = 'Microphone permission denied. Please enable it in browser settings.';
    } else if (errorMsg.includes('NotFoundError')) {
      displayError = 'No microphone found. Please connect one and try again.';
    }
    
    send({ type: 'ERROR', error: displayError });
  }
}, [send, session?.user?.id]);
```

#### **Pause Recording**
```typescript
const pauseRecording = useCallback(() => {
  if (mediaRecorderRef.current?.state === 'recording') {
    mediaRecorderRef.current.pause();
    send({ type: 'PAUSE' });
    console.log('â¸ï¸ Recording paused');
  }
}, [send]);
```

#### **Resume Recording**
```typescript
const resumeRecording = useCallback(() => {
  if (mediaRecorderRef.current?.state === 'paused') {
    mediaRecorderRef.current.resume();
    send({ type: 'RESUME' });
    console.log('â–¶ï¸ Recording resumed');
  }
}, [send]);
```

#### **Stop Recording** (most complex)
```typescript
const stopRecording = useCallback(() => {
  try {
    // 1. Stop MediaRecorder
    if (mediaRecorderRef.current?.state !== 'inactive') {
      mediaRecorderRef.current?.stop();
    }
    
    // 2. Stop microphone stream
    streamRef.current?.getTracks().forEach(track => track.stop());
    
    // 3. Clear session storage
    if (typeof window !== 'undefined') {
      localStorage.removeItem('currentSessionId');
      localStorage.removeItem('wasRecording');
    }
    
    // 4. Flush remaining chunks (if any)
    if (audioChunkQueueRef.current.length > 0) {
      console.log(`ğŸ“¤ Flushing ${audioChunkQueueRef.current.length} remaining chunks on stop`);
      audioChunkQueueRef.current.forEach(chunk => {
        socketRef.current?.emit('audio-chunk', chunk);
      });
      audioChunkQueueRef.current = [];
      setQueuedChunks(0);
    }
    
    // 5. Tell server to process
    socketRef.current?.emit('stop-session');
    
    // 6. Update state
    send({ type: 'STOP' }); // â†’ 'processing' state
    
    console.log('â¹ï¸ Recording stopped, waiting for summary...');
    
  } catch (error) {
    console.error('Stop recording error:', error);
    send({ type: 'ERROR', error: 'Failed to stop recording' });
  }
}, [send]);
```

#### **Return Hook Values**
```typescript
return {
  status: state.value,        // 'idle' | 'recording' | 'paused' | ...
  summary,                    // AI summary text (null until complete)
  liveTranscript,             // Accumulated live transcription
  error: state.context.error, // Error message (if any)
  queuedChunks,               // Number of buffered chunks
  startRecording,
  stopRecording,
  pauseRecording,
  resumeRecording,
};
```

---

### **4. [`app/components/client/machines/recorderMachine.ts`](app/components/client/machines/recorderMachine.ts ) - XState Machine**

**Purpose:** Centralized state management for recording lifecycle

**State Diagram:**
```
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    START     â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚     IDLE        â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
                â”‚                                         â”‚
         START  â”‚                                    STARTâ”‚
                â–¼                                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
         â”‚     RECORDING            â”‚                    â”‚
         â”‚   (user speaking)        â”‚                    â”‚
         â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
            â”‚       â”‚       â”‚                            â”‚
        PAUSEâ”‚       â”‚       â”‚ SERVER_      â”‚ STOP      â”‚
             â”‚       â”‚       â”‚DISCONNECT    â”‚           â”‚
             â–¼       â–¼       â–¼              â”‚           â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚          â”‚
         â”‚   PAUSED    â”‚  â”‚ RECONNECTINGâ”‚   â”‚          â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚          â”‚
            RESUMEâ”‚              â”‚           â”‚          â”‚
                  â”‚              â”‚ SERVER_   â”‚          â”‚
                  â”‚              â”‚CONNECTED  â”‚          â”‚
                  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚          â”‚
                         â”‚                   â”‚          â”‚
                         â”‚                   â–¼          â”‚
                         â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                         â”‚            â”‚  PROCESSING  â”‚  â”‚
                         â”‚            â”‚ (Gemini API) â”‚  â”‚
                         â”‚            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                         â”‚                   â”‚          â”‚
                         â”‚            COMPLETEâ”‚         â”‚
                         â”‚                   â–¼          â”‚
                         â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                         â”‚            â”‚   SUCCESS    â”‚â”€â”€â”´â”€ START (new)
                         â”‚            â”‚ (got summary)â”‚
                         â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                    STOP â”‚
                         â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚    ERROR     â”‚
                  â”‚ (mic denied) â”‚
                  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                    STARTâ”‚ (retry)
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ IDLE
```

**Machine Definition:**
```typescript
import { createMachine } from 'xstate';

export type RecorderContext = {
  sessionId: string | null;
  error: string | null;
  queuedChunks: number;
};

export type RecorderEvent =
  | { type: 'START'; sessionId: string }
  | { type: 'STOP' }
  | { type: 'PAUSE' }
  | { type: 'RESUME' }
  | { type: 'SERVER_CONNECTED' }
  | { type: 'SERVER_DISCONNECTED' }
  | { type: 'ERROR'; error: string }
  | { type: 'QUEUE_UPDATED'; count: number }
  | { type: 'COMPLETE' };

export const recorderMachine = createMachine({
  id: 'recorder',
  initial: 'idle',
  context: {
    sessionId: null,
    error: null,
    queuedChunks: 0,
  },
  states: {
    idle: {
      on: {
        START: {
          target: 'recording',
          actions: assign({ sessionId: (_, event) => event.sessionId }),
        },
      },
    },
    
    recording: {
      on: {
        PAUSE: 'paused',
        STOP: 'processing',
        SERVER_DISCONNECTED: 'reconnecting',
        ERROR: {
          target: 'error',
          actions: assign({ error: (_, event) => event.error }),
        },
        QUEUE_UPDATED: {
          actions: assign({ queuedChunks: (_, event) => event.count }),
        },
      },
    },
    
    paused: {
      on: {
        RESUME: 'recording',
        STOP: 'processing',
        ERROR: {
          target: 'error',
          actions: assign({ error: (_, event) => event.error }),
        },
      },
    },
    
    reconnecting: {
      on: {
        SERVER_CONNECTED: 'recording',
        STOP: 'processing',
        QUEUE_UPDATED: {
          actions: assign({ queuedChunks: (_, event) => event.count }),
        },
      },
    },
    
    processing: {
      on: {
        COMPLETE: 'success',
        ERROR: {
          target: 'error',
          actions: assign({ error: (_, event) => event.error }),
        },
      },
    },
    
    success: {
      on: {
        START: {
          target: 'recording',
          actions: assign({ 
            sessionId: (_, event) => event.sessionId,
            error: () => null, // Clear previous errors
          }),
        },
      },
    },
    
    error: {
      on: {
        START: {
          target: 'recording',
          actions: assign({
            sessionId: (_, event) => event.sessionId,
            error: () => null, // Clear error
          }),
        },
      },
    },
  },
});
```

**How It Works:**
1. User clicks "Start" â†’ `'idle'` â†’ `'recording'`
2. User clicks "Pause" â†’ `'recording'` â†’ `'paused'`
3. User clicks "Stop" â†’ (any state) â†’ `'processing'`
4. Server sends summary â†’ `'processing'` â†’ `'success'`
5. User clicks "New Recording" â†’ `'success'` â†’ `'recording'`

If network drops while recording:
- `useAudioStream` calls `send({ type: 'SERVER_DISCONNECTED' })`
- State â†’ `'reconnecting'`
- Chunks buffer locally
- When reconnected: `send({ type: 'SERVER_CONNECTED' })`
- State â†’ `'recording'`
- Buffered chunks flush automatically

---

### **5. [`server/server.ts`](server/server.ts ) - Backend Server**

**Purpose:** Accept audio chunks via Socket.IO, process with Gemini API, return transcription

**Server Setup:**
```typescript
import express from 'express';
import { createServer } from 'http';
import { Server as SocketIOServer } from 'socket.io';
import { GoogleGenerativeAI } from '@google/generative-ai';
import fs from 'fs';
import path from 'path';

const app = express();
const httpServer = createServer(app);
const io = new SocketIOServer(httpServer, {
  cors: {
    origin: 'http://localhost:3000',
    methods: ['GET', 'POST'],
  },
});

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash' });

// Active sessions tracked by sessionId
const activeSessions = new Map();

const PORT = 4000;
httpServer.listen(PORT, () => {
  console.log(`ğŸš€ Server running on port ${PORT}`);
});
```

#### **Event 1: start-session**
```typescript
io.on('connection', (socket) => {
  
  socket.on('start-session', async ({ sessionId, isResume, userId }) => {
    console.log(`ğŸ™ï¸ Session started: ${sessionId} (resume: ${isResume})`);
    
    try {
      // 1. Create database record
      if (!isResume && userId) {
        const recording = await prisma.recording.create({
          data: {
            sessionId,
            userId,
            filePath: `server/temp/${sessionId}.webm`,
            status: 'RECORDING',
          }
        });
        console.log(`ğŸ’¾ Created recording: ${recording.id}`);
      }
      
      // 2. Create file stream
      const tempDir = path.join(process.cwd(), 'server/temp');
      if (!fs.existsSync(tempDir)) {
        fs.mkdirSync(tempDir, { recursive: true });
      }
      
      const filePath = path.join(tempDir, `${sessionId}.webm`);
      const fileStream = fs.createWriteStream(filePath, {
        flags: isResume ? 'a' : 'w', // Append if resume, write if new
      });
      
      // 3. Store session info
      activeSessions.set(sessionId, {
        fileStream,
        socketId: socket.id,
        filePath,
        gracePeriodTimer: null,
        chunkBuffer: [],
        lastTranscriptionTime: Date.now(),
        isProcessing: false,
      });
      
      // 4. Update database
      await prisma.recording.update({
        where: { sessionId },
        data: { status: 'RECORDING' }
      });
      
      socket.emit('session-started', { sessionId });
      
    } catch (error) {
      console.error('Error starting session:', error);
      socket.emit('error', { message: 'Failed to start session' });
    }
  });
});
```

#### **Event 2: audio-chunk**
```typescript
socket.on('audio-chunk', async (chunk) => {
  const sessionId = /* get from context */;
  const session = activeSessions.get(sessionId);
  
  if (!session) {
    console.warn(`âš ï¸ Session not found: ${sessionId}`);
    return;
  }
  
  try {
    // 1. Write chunk to file immediately
    session.fileStream.write(chunk);
    console.log(`ğŸ“ Wrote chunk: ${chunk.size} bytes`);
    
    // 2. Buffer for live transcription
    session.chunkBuffer.push(Buffer.from(chunk));
    
    // 3. Every 5 seconds, send buffered audio to Gemini
    const now = Date.now();
    if (now - session.lastTranscriptionTime >= 5000) {
      session.lastTranscriptionTime = now;
      
      if (session.chunkBuffer.length > 0) {
        // Process asynchronously (don't block socket)
        processLiveChunk(sessionId, session, socket);
      }
    }
    
  } catch (error) {
    console.error('Error handling chunk:', error);
    socket.emit('error', { message: 'Failed to process audio chunk' });
  }
});

async function processLiveChunk(sessionId, session, socket) {
  try {
    // 1. Combine buffered chunks
    const audioBuffer = Buffer.concat(session.chunkBuffer);
    const tempChunkPath = `server/temp/${sessionId}-chunk-${Date.now()}.webm`;
    
    fs.writeFileSync(tempChunkPath, audioBuffer);
    
    // 2. Upload to Gemini
    const uploadResult = await fileManager.uploadFile(tempChunkPath);
    console.log(`ğŸ“¤ Uploaded to Gemini: ${uploadResult.file.uri}`);
    
    // 3. Get transcription
    const result = await model.generateContent([
      {
        fileData: {
          mimeType: 'audio/webm',
          fileUri: uploadResult.file.uri,
        }
      },
      { text: 'Transcribe this audio chunk concisely.' }
    ]);
    
    const liveText = result.response.text();
    console.log(`ğŸ“ Live transcript: ${liveText.substring(0, 50)}...`);
    
    // 4. Send to client
    socket.emit('live-transcript', { sessionId, text: liveText });
    
    // 5. Update database
    await prisma.recording.update({
      where: { sessionId },
      data: {
        liveTranscript: (previousTranscript || '') + ' ' + liveText,
        chunkCount: { increment: 1 }
      }
    });
    
    // 6. Clean up temp chunk
    fs.unlinkSync(tempChunkPath);
    session.chunkBuffer = [];
    
  } catch (error) {
    console.error('Live transcription error:', error);
    // Don't fail the session, just skip this chunk
  }
}
```

#### **Event 3: stop-session**
```typescript
socket.on('stop-session', async () => {
  const sessionId = /* get from context */;
  const session = activeSessions.get(sessionId);
  
  if (!session) return;
  
  try {
    // 1. Close file stream
    session.fileStream.end();
    console.log(`ğŸ“ Closed file: ${session.filePath}`);
    
    // 2. Mark as processing
    await prisma.recording.update({
      where: { sessionId },
      data: {
        status: 'PROCESSING',
        endedAt: new Date(),
      }
    });
    
    // 3. Process with Gemini (with retries)
    let success = false;
    let attempt = 0;
    let finalSummary = '';
    
    while (attempt < 3 && !success) {
      attempt++;
      try {
        // Upload full file
        const uploadResult = await fileManager.uploadFile(session.filePath);
        console.log(`ğŸš€ Attempt ${attempt}: Uploading to Gemini`);
        
        // Get transcription + summary
        const result = await model.generateContent([
          {
            fileData: {
              mimeType: 'audio/webm',
              fileUri: uploadResult.file.uri,
            }
          },
          {
            text: `You are an expert meeting transcriber. Analyze this audio and provide:

1. **Full Transcription** (speaker tags like [Speaker 1], [Speaker 2])
2. **Key Points** (3-5 bullet points)
3. **Action Items** (who, what, deadline)
4. **Decisions Made** (agreements reached)

Use Markdown formatting with clear headers (##).`
          }
        ]);
        
        finalSummary = result.response.text();
        console.log(`âœ… Transcription complete (${finalSummary.length} chars)`);
        
        // 4. Save to database
        await prisma.recording.update({
          where: { sessionId },
          data: {
            status: 'COMPLETED',
            transcript: finalSummary,
            summary: finalSummary,
            processedAt: new Date(),
            errorMessage: null,
          }
        });
        
        // 5. Send to client
        socket.emit('processing-complete', {
          sessionId,
          summary: finalSummary
        });
        
        // 6. Clean up temp file
        fs.unlinkSync(session.filePath);
        
        success = true;
        
      } catch (error) {
        console.error(`âŒ Attempt ${attempt} failed:`, error.message);
        
        if (attempt < 3) {
          // Exponential backoff: 2s, 4s, 8s
          await new Promise(r => setTimeout(r, 2000 * Math.pow(2, attempt - 1)));
        } else {
          // All retries exhausted
          throw error;
        }
      }
    }
    
    if (!success) {
      throw new Error('Failed to process audio after 3 attempts');
    }
    
  } catch (error) {
    console.error('Error stopping session:', error);
    
    // Mark as failed in database
    await prisma.recording.update({
      where: { sessionId },
      data: {
        status: 'FAILED',
        errorMessage: error.message
      }
    });
    
    // Notify client
    socket.emit('error', { message: 'Failed to process recording' });
    
  } finally {
    // Clean up
    activeSessions.delete(sessionId);
  }
});
```

#### **Event 4: disconnect** (grace period for reconnection)
```typescript
socket.on('disconnect', () => {
  const sessionId = /* get from context */;
  const session = activeSessions.get(sessionId);
  
  if (session) {
    console.log(`âš ï¸ Client disconnected: ${sessionId}`);
    
    // Start 30-second grace period
    session.gracePeriodTimer = setTimeout(() => {
      console.log(`ğŸ§¹ Grace period expired: ${sessionId}`);
      
      // Close file and cleanup
      session.fileStream.end();
      activeSessions.delete(sessionId);
    }, 30000);
  }
});

socket.on('reconnect', () => {
  const sessionId = /* get from context */;
  const session = activeSessions.get(sessionId);
  
  if (session && session.gracePeriodTimer) {
    console.log(`âœ… Client reconnected: ${sessionId}`);
    
    // Cancel grace period timer
    clearTimeout(session.gracePeriodTimer);
    session.gracePeriodTimer = null;
    
    // File continues to receive chunks
  }
});
```

---

### **6. [`prisma/schema.prisma`](prisma/schema.prisma ) - Database Schema**

**Purpose:** Define data models for user management and recording persistence

#### **User Model**
```prisma
model User {
  id            String    @id @default(cuid())
  name          String?
  email         String    @unique
  emailVerified Boolean?
  image         String?
  createdAt     DateTime  @default(now())
  updatedAt     DateTime  @updatedAt
  
  // Relations
  sessions      Session[]
  accounts      Account[]
  recordings    Recording[]  // â† User's recordings
}
```

**Fields:**
- `id` - Unique identifier (CUID format)
- `name` - Full name (optional)
- `email` - Email address (unique, used for sign in)
- `emailVerified` - Email confirmation status
- `image` - Profile picture URL (optional)
- `createdAt` - Account creation time
- `updatedAt` - Last updated time

#### **Recording Model** (NEW)
```prisma
model Recording {
  id            String   @id @default(cuid())
  sessionId     String   @unique
  userId        String
  
  // File Information
  filePath      String?               // Path to .webm file
  fileSize      Int?                  // Size in bytes
  duration      Int?                  // Duration in seconds
  mimeType      String   @default("audio/webm")
  
  // Transcription Results
  transcript    String?  @db.Text     // Full transcription from Gemini
  summary       String?  @db.Text     // AI summary (with key points, action items)
  liveTranscript String? @db.Text     // Accumulated live transcription chunks
  
  // Status Tracking
  status        RecordingStatus @default(RECORDING)
  
  // Timestamps
  startedAt     DateTime @default(now())
  endedAt       DateTime?              // When user stopped recording
  processedAt   DateTime?              // When Gemini finished processing
  
  // Metadata
  errorMessage  String?  @db.Text     // Error details if failed
  geminiTokensUsed Int?               // Tokens used by Gemini (for cost tracking)
  processingTimeMs Int?               // Time to generate summary
  chunkCount    Int      @default(0)  // Number of audio chunks processed
  
  createdAt     DateTime @default(now())
  updatedAt     DateTime @updatedAt
  
  // Relations
  user          User     @relation(fields: [userId], references: [id], onDelete: Cascade)
  
  @@index([userId])        // Fast lookup by user
  @@index([sessionId])     // Fast lookup by session
  @@index([status])        // Fast lookup by status
  @@map("recording")
}

enum RecordingStatus {
  RECORDING    // Currently recording
  PROCESSING   // Uploading to Gemini
  COMPLETED    // Successfully transcribed
  FAILED       // Error occurred
  PAUSED       // User paused (optional)
}
```

**Query Examples:**
```typescript
// Get all recordings for a user
const userRecordings = await prisma.recording.findMany({
  where: { userId: session.user.id },
  orderBy: { createdAt: 'desc' }
});

// Get latest completed recording
const lastRecording = await prisma.recording.findFirst({
  where: { userId, status: 'COMPLETED' },
  orderBy: { processedAt: 'desc' }
});

// Get all failed recordings (for debugging)
const failedRecordings = await prisma.recording.findMany({
  where: { status: 'FAILED' },
  include: { user: true }
});
```

---

## ğŸ”„ Complete User Flow

### **Scenario 1: Normal Recording** âœ…

```
USER                              CLIENT                        SERVER
  â”‚                                 â”‚                              â”‚
  â”œâ”€ Opens app                      â”‚                              â”‚
  â”‚                           useSession check                     â”‚
  â”‚                                 â”‚â—„â”€â”€â”€â”€â”€â”€â”€ Get session â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Better Auth
  â”‚                                 â”‚                              â”‚
  â”‚â—„â”€â”€â”€ Sign in form shows â”€â”€â”€â”€â”€â”€â”€â”€â”‚
  â”‚
  â”œâ”€ Enters email/password
  â”‚
  â”œâ”€ Clicks "Sign In"               â”‚                              â”‚
  â”‚                           handleAuth                           â”‚
  â”‚                                 â”‚â—„â”€ signIn.email() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Better Auth
  â”‚                                 â”‚                              â”‚
  â”‚â—„â”€â”€â”€ Session created â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                              â”‚
  â”‚
  â”‚â—„â”€â”€â”€ AudioRecorder shows â”€â”€â”€â”€â”€â”€â”€â”€â”‚                              â”‚
  â”‚                                 â”‚ useEffect: Socket init       â”‚
  â”‚                                 â”‚ (autoConnect: false)         â”‚
  â”‚
  â”œâ”€ Clicks "Start Recording"
  â”‚                           startRecording()
  â”‚                                 â”‚
  â”‚                           1. socket.connect()
  â”‚                                 â”‚â”€â”€â”€â”€â”€ Connection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Socket.IO
  â”‚                                 â”‚                              â”‚
  â”‚                           2. getUserMedia()
  â”‚                                 â”‚
  â”‚                           (Mic permission prompt)
  â”‚
  â”œâ”€ Approves microphone access
  â”‚
  â”‚                           3. Start MediaRecorder
  â”‚                           4. emit('start-session')
  â”‚                                 â”‚â”€ {sessionId, isResume, userId} â”€â”€â–ºâ”‚
  â”‚                                 â”‚                              â”‚
  â”‚                                 â”‚â—„â”€ session-started â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
  â”‚
  â”œâ”€ Starts speaking
  â”‚
  â”‚                           5. ondataavailable fires
  â”‚                              every 1000ms
  â”‚                                 â”‚
  â”‚                           emit('audio-chunk')
  â”‚                                 â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Write to file
  â”‚                                 â”‚                              â”‚ Buffer for live TX
  â”‚
  â”‚  [Repeat every 1000ms for duration]                             â”‚
  â”‚
  â”‚                           Every 5 seconds:
  â”‚                           â€¢ Buffer chunks
  â”‚                           â€¢ Upload to Gemini
  â”‚                                 â”‚                              â”‚
  â”‚                                 â”‚â—„â”€ live-transcript â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
  â”‚                                 â”‚  (e.g., "Hello, this is...")â”‚
  â”‚
  â”‚â—„â”€â”€â”€ Live transcript shows â”€â”€â”€â”€â”€â”‚
  â”‚
  â”œâ”€ Clicks "Stop"
  â”‚
  â”‚                           stopRecording()
  â”‚                                 â”‚
  â”‚                           â€¢ Stop MediaRecorder
  â”‚                           â€¢ Stop microphone
  â”‚                           â€¢ Flush remaining chunks
  â”‚                           â€¢ emit('stop-session')
  â”‚                                 â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Close file
  â”‚                                 â”‚                              â”‚ Update status: PROCESSING
  â”‚                                 â”‚                              â”‚
  â”‚                                 â”‚                              â”‚ Upload full .webm to Gemini
  â”‚                                 â”‚                              â”‚ Generate final summary
  â”‚                                 â”‚                              â”‚
  â”‚                                 â”‚                              â”‚ [Processing time: 30-60s]
  â”‚                                 â”‚                              â”‚
  â”‚                                 â”‚â—„â”€ processing-complete â”€â”€â”€â”€â”€â”‚
  â”‚                                 â”‚  {summary: "...full text..."}â”‚
  â”‚
  â”‚â—„â”€â”€â”€ AI Summary displays â”€â”€â”€â”€â”€â”€â”€â”‚
  â”‚
  â”œâ”€ Reads summary
  â”‚
  â”œâ”€ Clicks "Copy Summary"
  â”‚
  â”‚â—„â”€â”€â”€ Copied to clipboard â”€â”€â”€â”€â”€â”€â”€â”‚
  â”‚
  â””â”€ Done!
```

### **Scenario 2: Network Disconnection** ğŸŒ

```
USER                              CLIENT                        SERVER
  â”‚ [Recording in progress]
  â”‚
  â”‚  [WiFi drops]
  â”‚
  â”‚                           socket.on('disconnect')
  â”‚                                 â”‚
  â”‚                           Chunk buffering starts
  â”‚                           State: 'reconnecting'
  â”‚
  â”‚â—„â”€â”€â”€ Yellow banner shows â”€â”€â”€â”€â”€â”€â”€â”‚
  â”‚     "Connection Unstable"
  â”‚     "Buffering 3 chunks..."
  â”‚
  â”‚  [User continues speaking]
  â”‚
  â”‚                           MediaRecorder continues
  â”‚                           Chunks buffer in memory
  â”‚
  â”‚  [WiFi reconnects]
  â”‚
  â”‚                           socket.on('connect')
  â”‚                                 â”‚
  â”‚                           Flush buffered chunks
  â”‚                                 â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Write all chunks
  â”‚                                 â”‚                              â”‚
  â”‚                           State: 'recording'
  â”‚
  â”‚â—„â”€â”€â”€ Yellow banner disappears â”€â”‚
  â”‚
  â”‚  [Continue recording normally]
  â”‚
  â””â”€ No data lost!
```

### **Scenario 3: Tab Refresh During Recording** ğŸ”„

```
USER                              CLIENT                        SERVER
  â”‚ [Recording in progress]
  â”‚
  â”‚ localStorage.setItem('wasRecording', 'true')
  â”‚ localStorage.setItem('currentSessionId', 'session-123')
  â”‚
  â”œâ”€ Accidentally refreshes tab
  â”‚
  â”‚                           Page reload
  â”‚                           Usefulness check
  â”‚                                 â”‚
  â”‚                           useEffect detects:
  â”‚                           â€¢ wasRecording = true
  â”‚                           â€¢ sessionId saved
  â”‚                           â€¢ User logged in
  â”‚                                 â”‚
  â”‚                           Wait 1500ms, then:
  â”‚                           startRecording()
  â”‚                                 â”‚
  â”‚                           socket.connect()
  â”‚                                 â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
  â”‚                                 â”‚                              â”‚
  â”‚                           emit('start-session', {isResume: true})
  â”‚                                 â”‚â”€â”€â”€â”€ Same sessionId â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Append to existing file
  â”‚                                 â”‚                              â”‚
  â”‚â—„â”€â”€â”€ Recording resumes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                              â”‚
  â”‚                                 â”‚                              â”‚
  â”‚  [Old chunks + new chunks]
  â”‚                                 â”‚  âœ… Continuous recording!
  â”‚
  â””â”€ Session preserved!
```

---

## ğŸ› ï¸ Environment Configuration

### **Client `.env` (Next.js - Port 3000)**
```bash
# Authentication
NEXT_PUBLIC_APP_URL=http://localhost:3000

# API & Socket
NEXT_PUBLIC_SOCKET_URL=http://localhost:4000
NEXT_PUBLIC_API_URL=http://localhost:3000/api
```

### **Server `.env` (Node.js - Port 4000)**
```bash
# Port
PORT=4000

# Database
DATABASE_URL=postgresql://user:password@localhost:5432/audio_app

# Gemini API
GEMINI_API_KEY=your_api_key_here

# CORS
CLIENT_URL=http://localhost:3000
```

---

## ğŸš€ Running the Application

### **Terminal 1: Start Backend Server**
```bash
npm run dev
# Runs: tsx server/server.ts
# Starts on http://localhost:4000
```

### **Terminal 2: Start Frontend**
```bash
npm run dev:next
# Runs: next dev
# Starts on http://localhost:3000
```

### **Open Browser**
```
http://localhost:3000
```

---

## ğŸ“Š Current Issues & Solutions

### **Issue 1: Socket Connects Too Early** âŒ
**Problem:** Socket was connecting on component mount, causing infinite polling requests.

**Solution:** 
- Set `autoConnect: false` in socket options
- Manually call `socket.connect()` in `startRecording()`
- Only connect when user actually starts recording

### **Issue 2: Infinite Auto-Resume Loop** âŒ
**Problem:** `useEffect` dependencies on `state.value` caused infinite re-triggering.

**Solution:**
- Changed dependencies to only `[session?.user?.id]`
- Clear `wasRecording` flag immediately after reading
- Add state check `state.value === 'idle'` before resuming

### **Issue 3: Socket Disconnects Immediately After Connect** âŒ
**Problem:** Socket connects but then immediately disconnects, causing chunks to queue infinitely.

**Solution:**
- Wait for actual connection confirmation with promise
- Timeout after 5 seconds if connection fails
- Add error handling for connection errors

---

## ğŸ“ Summary

This is a production-ready audio transcription app with:

| Component | Technology | Purpose |
|-----------|-----------|---------|
| Frontend | Next.js 14 + React 18 | UI and state management |
| Real-time | Socket.IO | Bidirectional audio streaming |
| Audio | MediaRecorder API | Browser microphone access |
| State | XState 5.24 | Reliable state transitions |
| AI | Google Gemini 2.0 | Transcription and summarization |
| Database | PostgreSQL + Prisma | Data persistence |
| Auth | Better Auth | User authentication |
| Styling | Tailwind CSS | UI design |

**Key Strengths:**
- âœ… Real-time transcription during recording
- âœ… Automatic reconnection with chunk buffering
- âœ… Session persistence across tab refreshes
- âœ… AI-powered meeting summaries
- âœ… User authentication and multi-user support
- âœ… Robust error handling and recovery

---

**Last Updated:** November 26, 2025
